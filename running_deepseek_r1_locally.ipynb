{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running DeepSeek R1 locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to LM Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LM Studio is running!\n",
      "Available models: {'data': [{'id': 'deepseek-r1-distill-qwen-14b', 'object': 'model', 'owned_by': 'organization_owner'}, {'id': 'text-embedding-nomic-embed-text-v1.5', 'object': 'model', 'owned_by': 'organization_owner'}, {'id': 'deepseek-r1-distill-llama-8b', 'object': 'model', 'owned_by': 'organization_owner'}, {'id': 'deepseek-r1-distill-qwen-7b', 'object': 'model', 'owned_by': 'organization_owner'}], 'object': 'list'}\n"
     ]
    }
   ],
   "source": [
    "#@title Connecting to LM Studio\n",
    "import requests\n",
    "\n",
    "# Define LM Studio endpoint\n",
    "LM_STUDIO_URL = \"http://127.0.0.1:1234\"\n",
    "\n",
    "# Test that LM Studio is working\n",
    "try:\n",
    "    response = requests.get(f\"{LM_STUDIO_URL}/v1/models\")\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ LM Studio is running!\")\n",
    "        print(\"Available models:\", response.json())\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Unable to reach LM Studio. Make sure it's running.\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå LM Studio is not running. Start it and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing out a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ LM Studio: <think>\n",
      "Okay, so I need to figure out what the best fruit is. Hmm, that's a bit tricky because everyone has different preferences when it comes to fruits. Some people love bananas because they're easy to eat and portable, while others might prefer something like berries for their health benefits or maybe even tropical fruits like mangoes or pineapples if they enjoy something more exotic.\n",
      "\n",
      "I should consider factors like nutritional value, taste, availability, and versatility. Let's start by thinking about what makes a fruit \"good.\" Usually, fruits are rich in vitamins, minerals, fiber, and antioxidants, which contribute to overall health. Some fruits have unique benefits too, like bananas being good for the digestive system because of their fiber content.\n",
      "\n",
      "Bananas come to mind as a top choice because they're widely available almost everywhere, easy to eat on the go, and packed with nutrients like potassium, which is great for heart health. Plus, they're versatile in recipes‚Äîused in smoothies, baking, or just eaten raw. They have a natural sweetness that makes them satisfying without needing added sugar.\n",
      "\n",
      "On the other hand, berries like blueberries or strawberries are often praised for their high antioxidant content, which can help with things like improving brain function and reducing inflammation. But they might be more expensive or seasonal in some areas, making them less accessible to everyone.\n",
      "\n",
      "Then there's citrus fruits like oranges or lemons, which are known for their vitamin C content, boosting the immune system. However, they can sometimes be too acidic for people with certain dietary restrictions.\n",
      "\n",
      "I also think about tropical fruits like mangoes and pineapples that offer unique flavors but might not be as readily available everywhere, depending on where you live.\n",
      "\n",
      "Considering all these factors‚Äîavailability, nutritional benefits, taste, and versatility‚Äîit seems like bananas are a strong candidate. They're accessible to almost everyone, provide good energy, and have various uses in different types of meals or snacks.\n",
      "\n",
      "But wait, maybe I'm overlooking something. Are there any other fruits that offer more nutrients per serving? Let's think: avocados are sometimes considered a fruit and are high in healthy fats, but they might not be as sweet or portable. Grapes are another option, though they can have higher sugar content.\n",
      "\n",
      "Another angle is personal preference; what one person finds best could vary widely. So while bananas are a great choice for many reasons, the \"best\" fruit might really depend on individual needs and circumstances.\n",
      "\n",
      "In conclusion, after considering all these points, bananas seem like a well-rounded option because of their accessibility, nutritional value, and versatility in various diets and lifestyles.\n",
      "</think>\n",
      "\n",
      "The best fruit is subjective, but bananas stand out due to their high availability, portability, and nutritional benefits. They are rich in potassium, fiber, and natural sugars, making them ideal for energy and digestive health. Additionally, bananas are versatile in recipes and accessible worldwide, making them a top choice for many people.\n"
     ]
    }
   ],
   "source": [
    "#title Testing out a prompt\n",
    "prompt = \"What is the the best fruit? Choose one.\"\n",
    "\n",
    "llm_model = \"deepseek-r1-distill-qwen-14b\"\n",
    "max_tokens = 4096\n",
    "temperature = 0.7\n",
    "# Define the request payload for LM Studio\n",
    "payload = {\n",
    "    \"model\": llm_model,\n",
    "    \"promt\": prompt,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    \"max_tokens\": max_tokens,\n",
    "    \"temperature\": temperature\n",
    "}\n",
    "\n",
    "# Send the request to LM Studio\n",
    "response = requests.post(f\"{LM_STUDIO_URL}/v1/chat/completions\", json=payload)\n",
    "\n",
    "# Parse and print the response\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"ü§ñ LM Studio:\", result[\"choices\"][0][\"message\"][\"content\"])  # Fixed key\n",
    "else:\n",
    "    print(\"‚ùå Something went wrong:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ LM Studio (streaming): <think>\n",
      "Okay, so I need to explain what a black hole is in about 100 words. Hmm, where do I start? Well, from what I remember, a black hole is something in space that has really strong gravity. So strong that even light can't escape it, which is why it's called \"black\" because no light comes out. But wait, how does that work exactly?\n",
      "\n",
      "I think it starts with a star. When a massive star runs out of fuel, it can't support itself anymore and collapses. This collapse creates something super dense, maybe like a singularity? That sounds right. A singularity is a point where gravity is so intense that spacetime curves infinitely. But I'm not entirely sure about the details.\n",
      "\n",
      "So, the black hole has this event horizon, which is like the boundary around it. Anything that crosses the event horizon can't escape because the gravitational pull is too strong. Not even light, which means we can't see it directly. That's why they're called black holes‚Äîthey don't emit any light.\n",
      "\n",
      "But how do we know they exist if we can't see them? Oh right, through observations of their effects on surrounding space. Like stars orbiting something massive or the bending of light around it. Also, when matter gets too close to a black hole, it heats up and emits X-rays before getting pulled in. That's probably how scientists detect them indirectly.\n",
      "\n",
      "Wait, there are different types of black holes? I think some are stellar-mass, similar to stars, while others are supermassive at the centers of galaxies. And then there's something about spin and charge affecting their properties. But maybe that's beyond the 100-word limit.\n",
      "\n",
      "So putting it all together: a black hole is an object with immense gravity, formed from massive stars collapsing into singularities surrounded by event horizons. They don't emit light but affect their surroundings in detectable ways.\n",
      "</think>\n",
      "\n",
      "A black hole is a region in space where gravitational pull is so intense that nothing, not even light, can escape it. Formed when massive stars collapse into super-dense singularities, these cosmic phenomena are bordered by event horizons. Beyond this point, the force of gravity prevents anything from escaping. Though invisible, black holes' effects on surrounding matter and light allow us to detect them indirectly, such as through X-rays emitted by infalling material or gravitational interactions with nearby objects."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Define the parameters\n",
    "prompt = \"Explain in 100 words the concept of a black hole.\"\n",
    "llm_model = \"deepseek-r1-distill-qwen-14b\"\n",
    "max_tokens = 4090\n",
    "temperature = 0.7\n",
    "\n",
    "# Define the request payload\n",
    "payload = {\n",
    "    \"model\": llm_model,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Always answer in 100 words or less. You can ask for more information if needed.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    \"max_tokens\": max_tokens,\n",
    "    \"temperature\": temperature,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "# Send the request to LM Studio\n",
    "with requests.post(f\"{LM_STUDIO_URL}/v1/chat/completions\", json=payload, stream=True) as response:\n",
    "    if response.status_code == 200:\n",
    "        print(\"ü§ñ LM Studio (streaming): \", end=\"\", flush=True)\n",
    "        for line in response.iter_lines():\n",
    "            line = line.decode(\"utf-8\").strip()\n",
    "            if not line or line == \"data: [DONE]\":\n",
    "                continue  # Skip empty lines and [DONE] signal\n",
    "\n",
    "            if line.startswith(\"data: \"):\n",
    "                line = line[6:]  # Remove \"data: \" prefix\n",
    "\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                if \"choices\" in data and data[\"choices\"]:\n",
    "                    content = data[\"choices\"][0].get(\"delta\", {}).get(\"content\", \"\")\n",
    "                    if content:\n",
    "                        print(content, end=\"\", flush=True)\n",
    "                        sys.stdout.flush()  # Force Jupyter to show output\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"\\n‚ùå JSON Error: {e} - Raw Line: {line}\")\n",
    "                continue  # Skip invalid JSON\n",
    "    else:\n",
    "        print(\"‚ùå Something went wrong:\", response.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
